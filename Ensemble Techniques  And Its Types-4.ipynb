{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "847adbb7-db76-4977-981e-bb4bb638709c",
   "metadata": {},
   "source": [
    "Build a random forest classifier to predict the risk of heart disease based on a dataset of patient\n",
    "information. The dataset contains 303 instances with 14 features, including age, sex, chest pain type,\n",
    "resting blood pressure, serum cholesterol, and maximum heart rate achieved.\n",
    "\n",
    "Dataset link: https://drive.google.com/file/d/1bGoIE4Z2kG5nyh-fGZAJ7LH0ki3UfmSJ/view?\n",
    "usp=share_link\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33881c25-ec67-477d-9fc1-a88d1d5961c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.6.2)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (0.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.9.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (22.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Performance Metrics for Default Random Forest:\n",
      "Accuracy: 0.8241758241758241\n",
      "Precision: 0.8269230769230769\n",
      "Recall: 0.86\n",
      "F1 Score: 0.8431372549019608\n",
      "\n",
      "Top 5 most important features:\n",
      "    Feature  Importance\n",
      "10       ca    0.131861\n",
      "6   thalach    0.122198\n",
      "11     thal    0.119966\n",
      "8   oldpeak    0.104684\n",
      "0       age    0.099240\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn matplotlib seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the dataset\n",
    "data_url = 'https://drive.google.com/file/d/1bGoIE4Z2kG5nyh-fGZAJ7LH0ki3UfmSJ/view?usp=sharing'\n",
    "data_path = 'dataset.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Q1. Preprocess the dataset by handling missing values, encoding categorical variables, and scaling the numerical features if necessary.\n",
    "\n",
    "\n",
    "# Handle missing values (fill with mean or mode for simplicity)\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Encode categorical variables (one-hot encoding for 'cp' column)\n",
    "df = pd.get_dummies(df, columns=['cp'], drop_first=True)\n",
    "\n",
    "# Splitting the dataset into features (X) and target (y)\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Q2. Split the dataset into a training set (70%) and a test set (30%).\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Q3. Train a random forest classifier on the training set using 100 trees and a maximum depth of 10 for each tree. Use the default values for other hyperparameters.\n",
    "\n",
    "rf_model_default = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf_model_default.fit(X_train, y_train)\n",
    "\n",
    "# Q4. Evaluate the performance of the model on the test set using accuracy, precision, recall, and F1 score.\n",
    "y_pred = rf_model_default.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Performance Metrics for Default Random Forest:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Q5. Use the feature importance scores to identify the top 5 most important features in predicting heart disease risk. Visualise the feature importances using a bar chart.\n",
    "feature_importances = rf_model_default.feature_importances_\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "top_5_features = importance_df.nlargest(5, 'Importance')\n",
    "\n",
    "print(\"\\nTop 5 most important features:\")\n",
    "print(top_5_features)\n",
    "\n",
    "# Q6. Tune the hyperparameters of the random forest classifier using grid search or random search. Try different values of the number of trees, maximum depth, minimum samples split, and minimum samples leaf. Use 5-fold cross-validation to evaluate the performance of each set of hyperparameters.\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_model_tuned = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(rf_model_tuned, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Q7. Report the best set of hyperparameters found by the search and the corresponding performance metrics. Compare the performance of the tuned model with the default model.\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(\"\\nBest hyperparameters found by grid search:\")\n",
    "print(best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)\n",
    "\n",
    "# Evaluate the performance of the best model on the test set\n",
    "y_pred_tuned = best_model.predict(X_test)\n",
    "\n",
    "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "precision_tuned = precision_score(y_test, y_pred_tuned)\n",
    "recall_tuned = recall_score(y_test, y_pred_tuned)\n",
    "f1_tuned = f1_score(y_test, y_pred_tuned)\n",
    "\n",
    "print(\"\\nPerformance Metrics for Tuned Random Forest:\")\n",
    "print(\"Accuracy:\", accuracy_tuned)\n",
    "print(\"Precision:\", precision_tuned)\n",
    "print(\"Recall:\", recall_tuned)\n",
    "print(\"F1 Score:\", f1_tuned)\n",
    "\n",
    "# Q8. Interpret the model by analysing the decision boundaries of the random forest classifier. Plot the decision boundaries on a scatter plot of two of the most important features. Discuss the insights and limitations of the model for predicting heart disease risk.\n",
    "# Plot decision boundaries on a scatter plot of two most important features\n",
    "sns.scatterplot(data=df, x=top_5_features.iloc[0, 0], y=top_5_features.iloc[1, 0], hue='target', palette='Set1')\n",
    "plt.xlabel(top_5_features.iloc[0, 0])\n",
    "plt.ylabel(top_5_features.iloc[1, 0])\n",
    "plt.title(\"Decision Boundaries of Random Forest Classifier\")\n",
    "plt.legend(title='Target', labels=['No Heart Disease', 'Heart Disease'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d768ab2e-88b4-43b3-a1dd-6c72edbb4923",
   "metadata": {},
   "source": [
    "                      -------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
